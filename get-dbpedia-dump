#!/bin/sh
set -e

download() {
  DB_QUERY=$1
  TARGET_DIR=$2
  files=$(curl -s -H "Accept: text/csv" --data-urlencode "query=${DB_QUERY}" https://databus.dbpedia.org/repo/sparql | tail -n+2 | sed 's/"//g')
  for f in $files
  do
      originalArtifact=$(echo "$f" | grep -oP "(?!(.*/))(.*)$")
      artifact=$(echo "$originalArtifact" | sed -E 's/(\.bz2|\.gz)$//g')
      if [ ! -f "${TARGET_DIR}/${originalArtifact}" -a \
           ! -f "${TARGET_DIR}/${artifact}" ]; then
        echo "${TARGET_DIR}/${originalArtifact}"
        wget -NP $TARGET_DIR $f
      else
        echo "file '${originalArtifact}' already downloaded"
      fi
  done
}

get_dbpedia_dump() {
  VERSION=$1
  echo "
--------------------------------------------------------------------------------
                          DBPEDIA KG (${VERSION})
--------------------------------------------------------------------------------
"
  mkdir -p "data/dump"
  mkdir -p "data/ontology"

  if [ -f "data/ontology/ontology.nt" ]; then
    echo "ontology for DBPedia already downloaded"
  else
    echo "download ontology for DBPedia ..."
    ONT_QUERY=$(cat "query/ontology.query" | sed "s/DUMP_VERSION/${VERSION}/g")
    download "$ONT_QUERY" "data/ontology"
    mv "data/ontology/ontology--DEV_type=parsed.nt" "data/ontology/ontology.nt"
  fi

  echo "download data for DBPedia ..."
  DAT_QUERY=$(cat "query/data.query" | sed "s/DUMP_VERSION/${VERSION}/g")
  download "$DAT_QUERY" "data/dump"
  # Decompress BZip2 files
  for f in $(find -L data/dump -name "*.bz2")
  do
    echo "unpack $f"
    bzip2 -d "$f"
  done
  # Decompress GZip files
  for f in $(find -L data/dump -name "*.gz")
  do
    echo "unpack $f"
    gzip -d "$f"
  done
}

if [ -z "$1" ] ; then
  VERS=$(curl -s -H "Accept: text/csv" --data-urlencode "query=$(cat query/latest-dump.query)" https://databus.dbpedia.org/repo/sparql | tail -n+2 | sed 's/"//g')
  get_dbpedia_dump $VERS 
else
  get_dbpedia_dump $1
fi
